{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aceb5c0-f256-4416-8962-4ec276876bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# Keras 모델 로드\n",
    "model = tf.keras.models.load_model('keras_model.h5')\n",
    "\n",
    "# 음계와 대응하는 주파수 정의 (도, 레, 미, 파, 솔, 라, 시)\n",
    "notes = {\n",
    "    \"do\": 261,\n",
    "    \"re\": 293,\n",
    "    \"mi\": 329,\n",
    "    \"fa\": 349,\n",
    "    \"sol\": 392,\n",
    "    \"la\": 440,\n",
    "    \"si\": 493\n",
    "}\n",
    "\n",
    "# 현재 음높이 설정\n",
    "current_octave = 1\n",
    "\n",
    "def predict(frame):\n",
    "    # 프레임 전처리\n",
    "    img = cv2.resize(frame, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.float32(img) / 255.0\n",
    "\n",
    "    # 모델 예측\n",
    "    predictions = model.predict(img, verbose=0)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "def play_sound(note):\n",
    "    frequency = notes[note] * current_octave\n",
    "    duration = 250  # 250ms\n",
    "    winsound.Beep(frequency, duration)\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "prev_time = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 손동작 인식\n",
    "    current_time = time.time()\n",
    "    if current_time - prev_time >= 0.5:  # 0.5초마다 예측\n",
    "        predicted_class = predict(frame)\n",
    "        print(predicted_class)\n",
    "        prev_time = current_time\n",
    "\n",
    "        # 예측된 클래스에 따른 동작 수행\n",
    "        if predicted_class == 0:\n",
    "            play_sound(\"do\")\n",
    "        elif predicted_class == 1:\n",
    "            play_sound(\"re\")\n",
    "        elif predicted_class == 2:\n",
    "            play_sound(\"mi\")\n",
    "        elif predicted_class == 3:\n",
    "            play_sound(\"fa\")\n",
    "        elif predicted_class == 4:\n",
    "            play_sound(\"sol\")\n",
    "        elif predicted_class == 5:\n",
    "            play_sound(\"la\")\n",
    "        elif predicted_class == 6:\n",
    "            play_sound(\"si\")\n",
    "\n",
    "    # 프레임 표시\n",
    "    cv2.imshow('Hand Gesture Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b3f6b0e-e0ff-4f53-b761-15503aa232fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing sound: 도\n",
      "Playing sound: 도\n",
      "Playing sound: 도\n",
      "Playing sound: 도\n",
      "Playing sound: 도\n",
      "Playing sound: 레\n",
      "Playing sound: 레\n",
      "Playing sound: 레\n",
      "Playing sound: 레\n",
      "Playing sound: 레\n",
      "Playing sound: 미\n",
      "Playing sound: 미\n",
      "Playing sound: 미\n",
      "Playing sound: 미\n",
      "Playing sound: 미\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 파\n",
      "Playing sound: 솔\n",
      "Playing sound: 솔\n",
      "Playing sound: 솔\n",
      "Playing sound: 솔\n",
      "Playing sound: 솔\n",
      "Playing sound: 라\n",
      "Playing sound: 라\n",
      "Playing sound: 라\n",
      "Playing sound: 라\n",
      "Playing sound: 라\n",
      "Playing sound: 라\n",
      "Playing sound: 시\n",
      "Playing sound: 시\n",
      "Playing sound: 시\n",
      "Playing sound: 시\n",
      "Playing sound: 시\n",
      "Playing sound: 시\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "# Mediapipe 설정\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 음계와 대응하는 주파수 정의 (도, 레, 미, 파, 솔, 라, 시)\n",
    "notes = {\n",
    "    \"thumb_folded\": {\"note\": \"도\", \"frequency\": 261},\n",
    "    \"index_folded\": {\"note\": \"레\", \"frequency\": 293},\n",
    "    \"middle_folded\": {\"note\": \"미\", \"frequency\": 329},\n",
    "    \"ring_folded\": {\"note\": \"파\", \"frequency\": 349},\n",
    "    \"pinky_folded\": {\"note\": \"솔\", \"frequency\": 392},\n",
    "    \"only_thumb_stretched\": {\"note\": \"라\", \"frequency\": 440},\n",
    "    \"only_index_stretched\": {\"note\": \"시\", \"frequency\": 493}\n",
    "}\n",
    "\n",
    "def play_sound(note_info):\n",
    "    frequency = note_info[\"frequency\"]\n",
    "    note = note_info[\"note\"]\n",
    "    duration = 500  # 500ms\n",
    "    winsound.Beep(frequency, duration)\n",
    "    print(f\"Playing sound: {note}\")\n",
    "\n",
    "def is_finger_folded(hand_landmarks, finger_tip, finger_dip):\n",
    "    return hand_landmarks.landmark[finger_tip].y > hand_landmarks.landmark[finger_dip].y\n",
    "\n",
    "# 웹캠 설정\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Mediapipe 프레임 변환\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # 손가락 상태 확인\n",
    "            thumb_folded = is_finger_folded(hand_landmarks, mp_hands.HandLandmark.THUMB_TIP, mp_hands.HandLandmark.THUMB_IP)\n",
    "            index_folded = is_finger_folded(hand_landmarks, mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_DIP)\n",
    "            middle_folded = is_finger_folded(hand_landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_DIP)\n",
    "            ring_folded = is_finger_folded(hand_landmarks, mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_DIP)\n",
    "            pinky_folded = is_finger_folded(hand_landmarks, mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_DIP)\n",
    "\n",
    "            if thumb_folded and not index_folded and not middle_folded and not ring_folded and not pinky_folded:\n",
    "                play_sound(notes[\"thumb_folded\"])\n",
    "            elif index_folded and not thumb_folded and not middle_folded and not ring_folded and not pinky_folded:\n",
    "                play_sound(notes[\"index_folded\"])\n",
    "            elif middle_folded and not thumb_folded and not index_folded and not ring_folded and not pinky_folded:\n",
    "                play_sound(notes[\"middle_folded\"])\n",
    "            elif ring_folded and not thumb_folded and not index_folded and not middle_folded and not pinky_folded:\n",
    "                play_sound(notes[\"ring_folded\"])\n",
    "            elif pinky_folded and not thumb_folded and not index_folded and not middle_folded and not ring_folded:\n",
    "                play_sound(notes[\"pinky_folded\"])\n",
    "            elif not thumb_folded and not index_folded and middle_folded and ring_folded and not pinky_folded:\n",
    "                play_sound(notes[\"only_thumb_stretched\"])\n",
    "            elif not thumb_folded and not index_folded and not middle_folded and ring_folded and pinky_folded:\n",
    "                play_sound(notes[\"only_index_stretched\"])\n",
    "\n",
    "    # 프레임 표시\n",
    "    cv2.imshow('Hand Gesture Recognition', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # 0.5초 대기\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time.sleep(max(0, 0.5 - elapsed_time))\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec141769-87f8-45a1-8c28-8ffe3c71e96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
